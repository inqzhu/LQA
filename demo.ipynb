{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "引入需要的包\n",
    "\"\"\"\n",
    "# 引入pytorch相关的方法包\n",
    "import torch\n",
    "import torch.nn as nn # 构建网络相关函数\n",
    "import torch.optim as optim # 优化器\n",
    "from torch.utils.data import DataLoader # 数据加载器\n",
    "import torch.backends.cudnn as cudnn # cuda配置\n",
    "\n",
    "# 引入数据集导入、处理包\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 引入集合处理包，用于网络模型中包装网络层的序列\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 引入LQA包\n",
    "import LQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MNIST 数据集准备\n",
    "\"\"\"\n",
    "# MNIST 训练集\n",
    "data_train = MNIST('data/mnist',\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor()]))\n",
    "# MNIST 测试集\n",
    "data_test = MNIST('data/mnist',\n",
    "                  train=False,\n",
    "                  download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize((32, 32)),\n",
    "                      transforms.ToTensor()]))\n",
    "# 将2个数据集（训练集、测试集）加载为读取器\n",
    "data_train_loader = DataLoader(data_train, batch_size=64, shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(data_test, batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建网络模型\n",
    "\"\"\"\n",
    "# 示例：一个简单的MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        in_channels = 1\n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(1024, 1000)), # 输入层连接到第1个全连接层，1000个神经元\n",
    "            ('relu1', nn.ReLU()), # relu激活函数\n",
    "            ('f2', nn.Linear(1000, 1000)), # 第1个全连接层连接到第2个全连接层，1000个神经元\n",
    "            ('relu2', nn.ReLU()), # relu激活函数\n",
    "            ('f3', nn.Linear(1000, 10)) # 连接到输出层\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = img.view(img.size(0), -1) # 对输入的图像矩阵，先拉伸为一维向量\n",
    "        output = self.model(output) # 然后传入模型进行训练\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "模型训练准备工作：定义一次迭代时，训练、测试的方法\n",
    "\"\"\"\n",
    "\n",
    "# 设置cuda\n",
    "device = torch.device(\"cuda\") \n",
    "cudnn.benchmark = True \n",
    "# 设定pytorch的随机种子\n",
    "torch.manual_seed(1) \n",
    "\n",
    "# 定义模型训练的方法\n",
    "# 输入一个网络模型、损失函数、优化器、迭代次数，即可进行训练，更新网络参数估计\n",
    "def train(net, criterion, optimizer, epoch):\n",
    "    global device\n",
    "    \n",
    "    # 进入网络训练模式\n",
    "    net.train()\n",
    "    # 遍历训练集的每个 batch\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        # 获取每个 batch 的图像（images）及相应标签（labels），并通过【to(device)】放到GPU上\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        # 将 images 放入模型，通过模型得到预测的标签\n",
    "        output = net(images)\n",
    "        # 将预测的标签和真实标签对比，从而计算loss\n",
    "        loss = criterion(output, labels)\n",
    "        # 反向传播，得到梯度\n",
    "        loss.backward()   \n",
    "        \"\"\"\n",
    "        LQA\n",
    "        \"\"\"\n",
    "        # 代入优化器、模型、损失函数、当前的输入images和labels，以及当前迭代次数，计算出最优学习率\n",
    "        optimal_lr = LQA.LQA_delta(optimizer, net, criterion, images, labels, epoch)\n",
    "        # 优化器更新网络参数估计\n",
    "        optimizer.step()\n",
    "\n",
    "# 定义模型测试方法\n",
    "# 输入一个网络模型、损失函数、数据加载器、数据集，\n",
    "# 即可计算在该数据集上的平均loss、精度accuracy(ACC)\n",
    "def test(net, criterion, _data_loader, _dataset):\n",
    "    global device\n",
    "    # 测试时不需要反向传播更新参数，所以不计算梯度，减小计算开销\n",
    "    with torch.no_grad():\n",
    "        # 进入网络评价模式\n",
    "        net.eval()\n",
    "        # 为计算精度ACC、loss，准备相应的量\n",
    "        total_correct = 0\n",
    "        avg_loss = 0.0\n",
    "        # 遍历每个 batch 的数据\n",
    "        for i, (images, labels) in enumerate(_data_loader):\n",
    "            # 将 batch 数据放到GPU上\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 对网络输入 images 得到预测标签\n",
    "            output = net(images)\n",
    "            # 将损失函数的累和加到 avg_loss\n",
    "            avg_loss += criterion(output, labels).sum()\n",
    "            # 对每个输出（one-hot向量，例如[0,0,0,...,1]）换算成单个数值（例如 9）\n",
    "            pred = output.detach().max(1)[1]\n",
    "            # 通过比对换算后的数值与真实标签是否相等，计算 batch 上预测正确的个数\n",
    "            total_correct += pred.eq(labels.view_as(pred)).sum()\n",
    "        # 计算平均 loss\n",
    "        avg_loss /= len(_dataset)\n",
    "        # 将平均 loss 的值传递到CPU上\n",
    "        avg_loss_value = avg_loss.detach().cpu().item()\n",
    "        # 计算精度ACC （正确预测个数/样本总数）\n",
    "        acc = float(total_correct) / len(_dataset)\n",
    "        return [avg_loss_value, acc]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Epoch [0] | Train(loss: 0.002823 ACC: 0.9424) | Test(loss: 0.002955 ACC: 0.9382)\n",
      "** Epoch [1] | Train(loss: 0.001451 ACC: 0.9720) | Test(loss: 0.001664 ACC: 0.9682)\n",
      "** Epoch [2] | Train(loss: 0.000970 ACC: 0.9816) | Test(loss: 0.001272 ACC: 0.9733)\n",
      "** Epoch [3] | Train(loss: 0.000704 ACC: 0.9862) | Test(loss: 0.001066 ACC: 0.9786)\n",
      "** Epoch [4] | Train(loss: 0.000641 ACC: 0.9877) | Test(loss: 0.001071 ACC: 0.9789)\n",
      "** Epoch [5] | Train(loss: 0.000759 ACC: 0.9846) | Test(loss: 0.001268 ACC: 0.9760)\n",
      "** Epoch [6] | Train(loss: 0.000537 ACC: 0.9892) | Test(loss: 0.001036 ACC: 0.9776)\n",
      "** Epoch [7] | Train(loss: 0.000316 ACC: 0.9945) | Test(loss: 0.000893 ACC: 0.9813)\n",
      "** Epoch [8] | Train(loss: 0.000286 ACC: 0.9947) | Test(loss: 0.000846 ACC: 0.9833)\n",
      "** Epoch [9] | Train(loss: 0.000325 ACC: 0.9941) | Test(loss: 0.001031 ACC: 0.9791)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "模型迭代训练\n",
    "\"\"\"\n",
    "# 生成一个MLP模型，并放到GPU上\n",
    "net = MLP().to(device)\n",
    "# 指定损失函数为交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器为SGD，初始学习率为0.1\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-1)\n",
    "\n",
    "    \n",
    "# 迭代10次\n",
    "for epoch in range(0, 10):\n",
    "    # 单次迭代的过程\n",
    "    # 1.通过训练方法，训练、更新网络\n",
    "    train(net, criterion, optimizer, epoch) \n",
    "    # 2.通过测试方法，记录训练集上的 loss、ACC\n",
    "    [train_avg_loss, train_acc] = test(net, criterion, data_train_loader, data_train) \n",
    "    # 3.通过测试方法，记录测试集上的 loss\n",
    "    [test_avg_loss, test_acc] = test(net, criterion, data_test_loader, data_test) \n",
    "\n",
    "    # 显示当前训练情况\n",
    "    print('** Epoch [%d] | Train(loss: %f ACC: %.4f) | Test(loss: %f ACC: %.4f)' % \n",
    "          (epoch, train_avg_loss, train_acc, test_avg_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
